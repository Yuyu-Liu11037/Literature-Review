## Table of Contents
<table>
<tr><td colspan="2"><a href="#1-data" style="color:#B22222">1. Data</a></td></tr>
<tr>
  <td>&ensp;<a href="#11-distribution-imbalance">1.1 Distribution Imbalance</a></td>
  <td>&ensp;<a href="#12-data-homogeneity">1.2 Data Homogeneity</a></td>
</tr>
<tr>
  <td>&ensp;<a href="#13-annotation-irrelevance">1.3 Annotation Irrelevance</a></td>
</tr>

<tr><td colspan="2"><a href="#2-visual-encoder" style="color:#B22222">2. Visual Encoder</a></td></tr>

<tr><td colspan="2"><a href="#3-modality-aligning" style="color:#B22222">3. Modality Aligning</a></td></tr>

<tr><td colspan="2"><a href="#4-from-llm" style="color:#B22222">4. From LLM</a></td></tr>
<tr>
  <td>&ensp;<a href="#41-insufficient-context-attention">4.1 Insufficient Context Attention</a></td>
  <td>&ensp;<a href="#42-stochastic-sampling-decoding">4.2 Stochastic Sampling Decoding</a></td>
</tr>
<tr>
  <td>&ensp;<a href="#43-capability-misalignment">4.3 Capability Misalignment</a></td>
</tr>
</table>

## [1. Data](#content)
### [1.1 Distribution Imbalance](#content)
1. [Ciem: Contrastive instruction evaluation method for better instruction tuning](), NeurIPS workshop 2023, \
Hongyu Hu, Jiyuan Zhang, Minyi Zhao, et al.
1. [Mitigating hallucination in large multi-modal models via robust instruction tuning](), arXiv 2023, \
Fuxiao Liu, Kevin Lin, Linjie Li, et al.

### [1.2 Data Homogeneity](#content)
1. [Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback](), arXiv 2023, \
Tianyu Yu, Yuan Yao, Haoye Zhang, et al.
1. [Mitigating hallucination in large multi-modal models via robust instruction tuning](), arXiv 2023, \
Fuxiao Liu, Kevin Lin, Linjie Li, et al.

### [1.3 Annotation Irrelevance](#content)
1. [Mitigating hallucination in large multi-modal models via robust instruction tuning](), arXiv 2023, \
Fuxiao Liu, Kevin Lin, Linjie Li, et al.

## [2. Visual Encoder](#content)
1. [Halle-switch: Rethinking and controlling object existence hallucinations in large vision language models for detailed caption](), arXiv 2023, \
Bohan Zhai, Shijia Yang, Xiangchen Zhao
1. [Monkey: Image resolution and text label are important things for large multi-modal models](), arXiv 2023, \
Zhang Li, Biao Yang, Qiang Liu, et al.
1. [Vcoder: Versatile vision encoders for multimodal large language models](), arXiv 2023, \
Jitesh Jain, Jianwei Yang, and Humphrey Shi.
1. [Fine-grained image captioning with clip reward](), NAACL Findings 2022, \
Jaemin Cho, Seunghyun Yoon, Ajinkya Kale, et al.

## [3. Modality Aligning](#content)
1. [Aligning large multimodal models with factually augmented rlhf](), arXiv 2023, \
Zhiqing Sun, Sheng Shen, Shengcao Cao, et al.
1. [Beyond hallucinations: Enhancing lvlms through hallucination-aware direct preference optimization](), arXiv 2023, \
Zhiyuan Zhao, Bin Wang, Linke Ouyang, et al.
1. [Hallucination augmented contrastive learning for multimodal large language model](), arXiv 2023, \
Chaoya Jiang, Haiyang Xu, Mengfan Dong, et al.
1. [Woodpecker: Hallucination correction for multimodal large language models](), arXiv 2023, \
Shukang Yin, Chaoyou Fu, Sirui Zhao, et al.
1. [Internvl: Scaling up vision foundation models and aligning for generic visual-linguistic tasks](), arXiv 2023, \
Zhe Chen, Jiannan Wu, Wenhai Wang, et al.

## [4. From LLM](#content)
### [4.1 Insufficient Context Attention](#content)
1. [Vigc: Visual instruction generation and correction](), arXiv 2023, \
Bin Wang, Fan Wu, Xiao Han, et al.

### [4.2 Stochastic Sampling Decoding](#content)
1. [The curious case of neural text degeneration](), ICLR 2020, \
Ari Holtzman, Jan Buys, Li Du, et al.
1. [Neural path hunter: Reducing hallucination in dialogue systems via path grounding](), EMNLP 2021, \
Nouha Dziri, Andrea Madotto, Osmar R Zaiane, et al.

### [4.3 Capability Misalignment](#content)
1. [A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions](), ACM TIS 2024, \
Lei Huang, Weijiang Yu, Weitao Ma, et al.